{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Retrieval-Augmented Question Answering with LLMs\n",
    "\n",
    "In this assignment, we will use a large language model (LLM) in a retrieval-augmented setup to answer questions from the Natural Questions dataset. We will evaluate the performance of the LLM using different prompting strategies and compare the results. The steps involved are as follows:\n",
    "\n",
    "1. **Evaluate an LLM on Natural Questions without context.**\n",
    "2. **Evaluate an LLM on Natural Questions with provided context.**\n",
    "3. **Set up a retriever to find relevant passages.**\n",
    "4. **Evaluate the LLM using retrieved context instead of provided context.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>gold_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what purpose did seasonal monsoon winds have o...</td>\n",
       "      <td>enabled European empire expansion into the Ame...</td>\n",
       "      <td>The westerlies (blue arrows) and trade winds (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who got the first nobel prize in physics</td>\n",
       "      <td>Wilhelm Conrad Röntgen, of Germany</td>\n",
       "      <td>The award is presented in Stockholm at an annu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when is the next deadpool movie being released</td>\n",
       "      <td>May 18, 2018</td>\n",
       "      <td>Though the original creative team of Reynolds,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where did the idea of fortnite come from</td>\n",
       "      <td>as a cross between Minecraft and Left 4 Dead</td>\n",
       "      <td>Fortnite is set in contemporary Earth, where t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which mode is used for short wave broadcast se...</td>\n",
       "      <td>MFSK Olivia</td>\n",
       "      <td>All one needs is a pair of transceivers, each ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  what purpose did seasonal monsoon winds have o...   \n",
       "1           who got the first nobel prize in physics   \n",
       "2     when is the next deadpool movie being released   \n",
       "3           where did the idea of fortnite come from   \n",
       "4  which mode is used for short wave broadcast se...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  enabled European empire expansion into the Ame...   \n",
       "1                 Wilhelm Conrad Röntgen, of Germany   \n",
       "2                                       May 18, 2018   \n",
       "3       as a cross between Minecraft and Left 4 Dead   \n",
       "4                                        MFSK Olivia   \n",
       "\n",
       "                                        gold_context  \n",
       "0  The westerlies (blue arrows) and trade winds (...  \n",
       "1  The award is presented in Stockholm at an annu...  \n",
       "2  Though the original creative team of Reynolds,...  \n",
       "3  Fortnite is set in contemporary Earth, where t...  \n",
       "4  All one needs is a pair of transceivers, each ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "nq_data = pd.read_csv('nq_simplified.val.tsv', sep='\\t', header=None, names=['question', 'answer', 'gold_context'], quoting=3)\n",
    "\n",
    "nq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge1(gold, predicted):\n",
    "    assert(len(gold) == len(predicted))\n",
    "    n_p = 0\n",
    "    n_g = 0\n",
    "    n_c = 0\n",
    "    for g, p in zip(gold, predicted):\n",
    "        g = set(cleanup(g).strip().split())\n",
    "        p = set(cleanup(p).strip().split())\n",
    "        n_g += len(g)\n",
    "        n_p += len(p)\n",
    "        n_c += len(p.intersection(g))\n",
    "    pr = n_c / n_p\n",
    "    re = n_c / n_g\n",
    "    if pr > 0 and re > 0:\n",
    "        f1 = 2*pr*re/(pr + re)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    return pr, re, f1\n",
    "\n",
    "def cleanup(text):\n",
    "    text = text.replace(',', ' ')\n",
    "    text = text.replace('.', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Evaluating an LLM on Natural Questions\n",
    "\n",
    "First, we will find an LLM on huginface hub that is small and fast to fitt on our system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the model and tokenizer\n",
    " \"mistralai/Mixtral-8x7B-Instruct-v0.1\" \"microsoft/Phi-3-mini-4k-instruct\" \"mtgv/MobileLLaMA-1.4B-Base\" \"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\" \n",
    "\"TheBloke/Llama-2-7B-Chat-AWQ\"\n",
    "\n",
    "\"\"\"\n",
    "model_name = \"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a simple pipline for QA and use a small subset of the dataset to get the predicted answers and evaluate the model using ROUGE-1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Rouge-1 Precision</th>\n",
       "      <th>Rouge-1 Recall</th>\n",
       "      <th>Rouge-1 F1</th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0.247706</td>\n",
       "      <td>0.074483</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] {} [/INST]</td>\n",
       "      <td>0.050388</td>\n",
       "      <td>0.298165</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] {} [/INST] Answer:</td>\n",
       "      <td>0.054357</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.092580</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt;[INST] You are a question answering system....</td>\n",
       "      <td>0.076065</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.124585</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt;Question: {} [INST]Generate a short-form an...</td>\n",
       "      <td>0.067293</td>\n",
       "      <td>0.197248</td>\n",
       "      <td>0.100350</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.101950</td>\n",
       "      <td>0.527523</td>\n",
       "      <td>0.170877</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.110522</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.185322</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.113430</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.132495</td>\n",
       "      <td>0.628440</td>\n",
       "      <td>0.218850</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.385321</td>\n",
       "      <td>0.219321</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.074697</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.124127</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.063439</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.067663</td>\n",
       "      <td>0.353211</td>\n",
       "      <td>0.113569</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.077876</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.130564</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.084886</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>0.116976</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;s&gt; Context: {}\\n Question: {} [INST] Select t...</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.233945</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[INST] {} [/INST]</td>\n",
       "      <td>0.046709</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.078060</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[INST] {} [/INST] Answer:</td>\n",
       "      <td>0.049135</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;s&gt;[INST] You are a question answering system....</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>0.276978</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;s&gt;Question: {} [INST]Generate a short-form an...</td>\n",
       "      <td>0.061924</td>\n",
       "      <td>0.169065</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Prompt  Rouge-1 Precision  \\\n",
       "0                                                  {}           0.043831   \n",
       "1                                   [INST] {} [/INST]           0.050388   \n",
       "2                           [INST] {} [/INST] Answer:           0.054357   \n",
       "3   <s>[INST] You are a question answering system....           0.076065   \n",
       "4   <s>Question: {} [INST]Generate a short-form an...           0.067293   \n",
       "5                   Context:{}, Question: {}, Answer:           0.101950   \n",
       "6              [INST] Context:{}\\n Question:{}[/INST]           0.110522   \n",
       "7      [INST] Context:{}\\n Question:{}[/INST] Answer:           0.113430   \n",
       "8   <s>Context:{}\\n [INST] You are a question answ...           0.132495   \n",
       "9   <s>Context:{}\\n Question:{} [INST] Using the i...           0.153285   \n",
       "10                  Context:{}, Question: {}, Answer:           0.074697   \n",
       "11             [INST] Context:{}\\n Question:{}[/INST]           0.063439   \n",
       "12     [INST] Context:{}\\n Question:{}[/INST] Answer:           0.067663   \n",
       "13  <s>Context:{}\\n [INST] You are a question answ...           0.077876   \n",
       "14  <s>Context:{}\\n Question:{} [INST] Using the i...           0.084886   \n",
       "15  <s> Context: {}\\n Question: {} [INST] Select t...           0.041565   \n",
       "16                                                 {}           0.049600   \n",
       "17                                  [INST] {} [/INST]           0.046709   \n",
       "18                          [INST] {} [/INST] Answer:           0.049135   \n",
       "19  <s>[INST] You are a question answering system....           0.056535   \n",
       "20  <s>Question: {} [INST]Generate a short-form an...           0.061924   \n",
       "\n",
       "    Rouge-1 Recall  Rouge-1 F1           Method                         Model  \\\n",
       "0         0.247706    0.074483  without context           Llama-2-7B-Chat-AWQ   \n",
       "1         0.298165    0.086207  without context           Llama-2-7B-Chat-AWQ   \n",
       "2         0.311927    0.092580  without context           Llama-2-7B-Chat-AWQ   \n",
       "3         0.344037    0.124585  without context           Llama-2-7B-Chat-AWQ   \n",
       "4         0.197248    0.100350  without context           Llama-2-7B-Chat-AWQ   \n",
       "5         0.527523    0.170877     with context           Llama-2-7B-Chat-AWQ   \n",
       "6         0.573394    0.185322     with context           Llama-2-7B-Chat-AWQ   \n",
       "7         0.573394    0.189394     with context           Llama-2-7B-Chat-AWQ   \n",
       "8         0.628440    0.218850     with context           Llama-2-7B-Chat-AWQ   \n",
       "9         0.385321    0.219321     with context           Llama-2-7B-Chat-AWQ   \n",
       "10        0.366972    0.124127        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "11        0.348624    0.107345        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "12        0.353211    0.113569        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "13        0.403670    0.130564        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "14        0.188073    0.116976        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "15        0.233945    0.070588        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "16        0.223022    0.081152  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "17        0.237410    0.078060  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "18        0.255396    0.082414  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "19        0.276978    0.093902  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "20        0.169065    0.090646  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "\n",
       "    Sample Size  \n",
       "0            50  \n",
       "1            50  \n",
       "2            50  \n",
       "3            50  \n",
       "4            50  \n",
       "5            50  \n",
       "6            50  \n",
       "7            50  \n",
       "8            50  \n",
       "9            50  \n",
       "10           50  \n",
       "11           50  \n",
       "12           50  \n",
       "13           50  \n",
       "14           50  \n",
       "15           50  \n",
       "16           50  \n",
       "17           50  \n",
       "18           50  \n",
       "19           50  \n",
       "20           50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 15s, sys: 148 ms, total: 5min 15s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a pipeline for question answering\n",
    "qa_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False, \n",
    "                       pad_token_id=tokenizer.eos_token_id, max_new_tokens=400,)\n",
    "\n",
    "# Define a function to get answers from the model\n",
    "def get_answers(questions, prompt, max_new_tokens):\n",
    "    answers = []\n",
    "    for question in questions:\n",
    "        p = prompt.format(question) \n",
    "        response = qa_pipeline(p,max_new_tokens=max_new_tokens)\n",
    "        answers.append(response[0]['generated_text'])\n",
    "    return answers\n",
    "\n",
    "# Use a small subset of the dataset for testing\n",
    "prompts = [ \n",
    "    \"{}\",\n",
    "    '[INST] {} [/INST]',\n",
    "    '[INST] {} [/INST] Answer:',\n",
    "    '<s>[INST] You are a question answering system. Please give a short answer to the following user question.[/INST] Question: {}',\n",
    "    '<s>Question: {} [INST]Generate a short-form answer of either one word or one sentence to the question.[/INST]',\n",
    "          ]\n",
    "subset = nq_data.sample(50)\n",
    "questions = subset['question'].tolist()\n",
    "gold_answers = subset['answer'].tolist()\n",
    "results=[]\n",
    "for prompt in prompts:\n",
    "    predicted_answers = get_answers(questions, prompt,max_new_tokens=50)\n",
    "    pr, re, f1 = rouge1(gold_answers, predicted_answers)\n",
    "    answer = [prompt, pr, re, f1, \"without context\", \"Mistral-7B-Instruct-v0.2-AWQ\", 50]\n",
    "    results.append(answer)\n",
    "result_1 = pd.DataFrame(results, columns=['Prompt', 'Rouge-1 Precision', 'Rouge-1 Recall', 'Rouge-1 F1', 'Method', 'Model', 'Sample Size',])\n",
    "result = pd.concat([result, result_1], ignore_index=True)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: An Idealized Retrieval-Augmented LLM\n",
    "\n",
    "Now, we will include the `gold_context` in our prompts and evaluate the model again. This will help us understand the upper limits of the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 10s, sys: 1.39 s, total: 5min 11s\n",
      "Wall time: 5min 11s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Rouge-1 Precision</th>\n",
       "      <th>Rouge-1 Recall</th>\n",
       "      <th>Rouge-1 F1</th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0.247706</td>\n",
       "      <td>0.074483</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] {} [/INST]</td>\n",
       "      <td>0.050388</td>\n",
       "      <td>0.298165</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] {} [/INST] Answer:</td>\n",
       "      <td>0.054357</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.092580</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt;[INST] You are a question answering system....</td>\n",
       "      <td>0.076065</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.124585</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt;Question: {} [INST]Generate a short-form an...</td>\n",
       "      <td>0.067293</td>\n",
       "      <td>0.197248</td>\n",
       "      <td>0.100350</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.101950</td>\n",
       "      <td>0.527523</td>\n",
       "      <td>0.170877</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.110522</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.185322</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.113430</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.132495</td>\n",
       "      <td>0.628440</td>\n",
       "      <td>0.218850</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.385321</td>\n",
       "      <td>0.219321</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.074697</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.124127</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.063439</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.067663</td>\n",
       "      <td>0.353211</td>\n",
       "      <td>0.113569</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.077876</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.130564</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.084886</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>0.116976</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;s&gt; Context: {}\\n Question: {} [INST] Select t...</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.233945</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[INST] {} [/INST]</td>\n",
       "      <td>0.046709</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.078060</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[INST] {} [/INST] Answer:</td>\n",
       "      <td>0.049135</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;s&gt;[INST] You are a question answering system....</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>0.276978</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;s&gt;Question: {} [INST]Generate a short-form an...</td>\n",
       "      <td>0.061924</td>\n",
       "      <td>0.169065</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.135947</td>\n",
       "      <td>0.586331</td>\n",
       "      <td>0.220718</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.138449</td>\n",
       "      <td>0.629496</td>\n",
       "      <td>0.226978</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.142972</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>0.233749</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.158192</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.258405</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.543165</td>\n",
       "      <td>0.293774</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Prompt  Rouge-1 Precision  \\\n",
       "0                                                  {}           0.043831   \n",
       "1                                   [INST] {} [/INST]           0.050388   \n",
       "2                           [INST] {} [/INST] Answer:           0.054357   \n",
       "3   <s>[INST] You are a question answering system....           0.076065   \n",
       "4   <s>Question: {} [INST]Generate a short-form an...           0.067293   \n",
       "5                   Context:{}, Question: {}, Answer:           0.101950   \n",
       "6              [INST] Context:{}\\n Question:{}[/INST]           0.110522   \n",
       "7      [INST] Context:{}\\n Question:{}[/INST] Answer:           0.113430   \n",
       "8   <s>Context:{}\\n [INST] You are a question answ...           0.132495   \n",
       "9   <s>Context:{}\\n Question:{} [INST] Using the i...           0.153285   \n",
       "10                  Context:{}, Question: {}, Answer:           0.074697   \n",
       "11             [INST] Context:{}\\n Question:{}[/INST]           0.063439   \n",
       "12     [INST] Context:{}\\n Question:{}[/INST] Answer:           0.067663   \n",
       "13  <s>Context:{}\\n [INST] You are a question answ...           0.077876   \n",
       "14  <s>Context:{}\\n Question:{} [INST] Using the i...           0.084886   \n",
       "15  <s> Context: {}\\n Question: {} [INST] Select t...           0.041565   \n",
       "16                                                 {}           0.049600   \n",
       "17                                  [INST] {} [/INST]           0.046709   \n",
       "18                          [INST] {} [/INST] Answer:           0.049135   \n",
       "19  <s>[INST] You are a question answering system....           0.056535   \n",
       "20  <s>Question: {} [INST]Generate a short-form an...           0.061924   \n",
       "21                  Context:{}, Question: {}, Answer:           0.135947   \n",
       "22             [INST] Context:{}\\n Question:{}[/INST]           0.138449   \n",
       "23     [INST] Context:{}\\n Question:{}[/INST] Answer:           0.142972   \n",
       "24  <s>Context:{}\\n [INST] You are a question answ...           0.158192   \n",
       "25  <s>Context:{}\\n Question:{} [INST] Using the i...           0.201333   \n",
       "\n",
       "    Rouge-1 Recall  Rouge-1 F1           Method                         Model  \\\n",
       "0         0.247706    0.074483  without context           Llama-2-7B-Chat-AWQ   \n",
       "1         0.298165    0.086207  without context           Llama-2-7B-Chat-AWQ   \n",
       "2         0.311927    0.092580  without context           Llama-2-7B-Chat-AWQ   \n",
       "3         0.344037    0.124585  without context           Llama-2-7B-Chat-AWQ   \n",
       "4         0.197248    0.100350  without context           Llama-2-7B-Chat-AWQ   \n",
       "5         0.527523    0.170877     with context           Llama-2-7B-Chat-AWQ   \n",
       "6         0.573394    0.185322     with context           Llama-2-7B-Chat-AWQ   \n",
       "7         0.573394    0.189394     with context           Llama-2-7B-Chat-AWQ   \n",
       "8         0.628440    0.218850     with context           Llama-2-7B-Chat-AWQ   \n",
       "9         0.385321    0.219321     with context           Llama-2-7B-Chat-AWQ   \n",
       "10        0.366972    0.124127        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "11        0.348624    0.107345        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "12        0.353211    0.113569        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "13        0.403670    0.130564        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "14        0.188073    0.116976        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "15        0.233945    0.070588        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "16        0.223022    0.081152  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "17        0.237410    0.078060  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "18        0.255396    0.082414  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "19        0.276978    0.093902  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "20        0.169065    0.090646  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "21        0.586331    0.220718     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "22        0.629496    0.226978     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "23        0.640288    0.233749     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "24        0.705036    0.258405     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "25        0.543165    0.293774     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "\n",
       "    Sample Size  \n",
       "0            50  \n",
       "1            50  \n",
       "2            50  \n",
       "3            50  \n",
       "4            50  \n",
       "5            50  \n",
       "6            50  \n",
       "7            50  \n",
       "8            50  \n",
       "9            50  \n",
       "10           50  \n",
       "11           50  \n",
       "12           50  \n",
       "13           50  \n",
       "14           50  \n",
       "15           50  \n",
       "16           50  \n",
       "17           50  \n",
       "18           50  \n",
       "19           50  \n",
       "20           50  \n",
       "21           50  \n",
       "22           50  \n",
       "23           50  \n",
       "24           50  \n",
       "25           50  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Define a function to get answers from the model with context\n",
    "def get_answers_with_context(questions, contexts, prompt, max_new_tokens):\n",
    "    answers = []\n",
    "    for question, context in zip(questions, contexts):\n",
    "        p = prompt.format(context,question) \n",
    "        response = qa_pipeline(p, max_new_tokens=max_new_tokens)\n",
    "        answers.append(response[0]['generated_text'])\n",
    "    return answers\n",
    "\n",
    "contexts = subset['gold_context'].tolist()\n",
    "\n",
    "prompts = [ \n",
    "    'Context:{}, Question: {}, Answer:',\n",
    "    '[INST] Context:{}\\n Question:{}[/INST]',\n",
    "    '[INST] Context:{}\\n Question:{}[/INST] Answer:',\n",
    "    '<s>Context:{}\\n [INST] You are a question answering system. Based on the above context, generate a short answer to the following question.[/INST]\\n Question: {}',\n",
    "    '<s>Context:{}\\n Question:{} [INST] Using the information provided in the context, generate a short-form answer of either one word or one sentence to the question. [/INST]',\n",
    "          ]\n",
    "results=[]\n",
    "for prompt in prompts:\n",
    "    predicted_answers_with_context = get_answers_with_context(questions, contexts, prompt, max_new_tokens=50)\n",
    "    pr_context, re_context, f1_context = rouge1(gold_answers, predicted_answers_with_context)\n",
    "    answer = [prompt, pr_context, re_context, f1_context, \"with context\", \"Mistral-7B-Instruct-v0.2-AWQ\", 50]\n",
    "    results.append(answer)\n",
    "result_2 = pd.DataFrame(results, columns=['Prompt', 'Rouge-1 Precision', 'Rouge-1 Recall', 'Rouge-1 F1', 'Method', 'Model', 'Sample Size'])\n",
    "result = pd.concat([result, result_2], ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setting Up the Retriever\n",
    "\n",
    "In this step, we will set up a retriever to find relevant passages. We will use the SentenceTransformers model to create embeddings for the passages and set up a FAISS index for efficient retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "retriever_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "with open('passages.txt', 'r', encoding='utf-8') as file:\n",
    "    passages = file.readlines()\n",
    "\n",
    "embedded_passages = retriever_model.encode(passages, convert_to_tensor=True)\n",
    "\n",
    "index = faiss.IndexFlatL2(embedded_passages.shape[1])\n",
    "index.add(embedded_passages.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Passage: Black Americans were not permitted to fly for the U.S. armed services prior to 1940. The Air Corps at that time, which had never had a single black member, was part of an army that possessed exactly two black Regular line officers at the beginning of World War II: Brigadier Generals Benjamin O. Davis, Sr. and Benjamin O. Davis, Jr. The first Civilian Pilot Training Program (CPTP) students completed their instruction in May 1940. The creation of an all-black pursuit squadron resulted from pressure by civil rights organizations and the black press who pushed for the establishment of a unit at Tuskegee, an\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def retrieve_best_passage(question):\n",
    "    question_embedding = retriever_model.encode([question], convert_to_tensor=True)\n",
    "    _, ix = index.search(question_embedding.cpu(), 1)\n",
    "    return passages[ix[0][0]]\n",
    "\n",
    "question = \"Where did the first African American air force unit train?\"\n",
    "best_passage = retrieve_best_passage(question)\n",
    "print(f\"Best Passage: {best_passage}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Putting the Pieces Together\n",
    "\n",
    "Finally, we will retrieve passages for each question and evaluate the model using these passages instead of the provided `gold_context`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Rouge-1 Precision</th>\n",
       "      <th>Rouge-1 Recall</th>\n",
       "      <th>Rouge-1 F1</th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0.247706</td>\n",
       "      <td>0.074483</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] {} [/INST]</td>\n",
       "      <td>0.050388</td>\n",
       "      <td>0.298165</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] {} [/INST] Answer:</td>\n",
       "      <td>0.054357</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.092580</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt;[INST] You are a question answering system....</td>\n",
       "      <td>0.076065</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.124585</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt;Question: {} [INST]Generate a short-form an...</td>\n",
       "      <td>0.067293</td>\n",
       "      <td>0.197248</td>\n",
       "      <td>0.100350</td>\n",
       "      <td>without context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.101950</td>\n",
       "      <td>0.527523</td>\n",
       "      <td>0.170877</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.110522</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.185322</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.113430</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.132495</td>\n",
       "      <td>0.628440</td>\n",
       "      <td>0.218850</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.385321</td>\n",
       "      <td>0.219321</td>\n",
       "      <td>with context</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.074697</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.124127</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.063439</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.067663</td>\n",
       "      <td>0.353211</td>\n",
       "      <td>0.113569</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.077876</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.130564</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.084886</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>0.116976</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;s&gt; Context: {}\\n Question: {} [INST] Select t...</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.233945</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Llama-2-7B-Chat-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[INST] {} [/INST]</td>\n",
       "      <td>0.046709</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.078060</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[INST] {} [/INST] Answer:</td>\n",
       "      <td>0.049135</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;s&gt;[INST] You are a question answering system....</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>0.276978</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;s&gt;Question: {} [INST]Generate a short-form an...</td>\n",
       "      <td>0.061924</td>\n",
       "      <td>0.169065</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>without context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.135947</td>\n",
       "      <td>0.586331</td>\n",
       "      <td>0.220718</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.138449</td>\n",
       "      <td>0.629496</td>\n",
       "      <td>0.226978</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.142972</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>0.233749</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.158192</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.258405</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.543165</td>\n",
       "      <td>0.293774</td>\n",
       "      <td>with context</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Context:{}, Question: {}, Answer:</td>\n",
       "      <td>0.081210</td>\n",
       "      <td>0.366906</td>\n",
       "      <td>0.132986</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST]</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.327338</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[INST] Context:{}\\n Question:{}[/INST] Answer:</td>\n",
       "      <td>0.061639</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.102595</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n [INST] You are a question answ...</td>\n",
       "      <td>0.059172</td>\n",
       "      <td>0.287770</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;s&gt;Context:{}\\n Question:{} [INST] Using the i...</td>\n",
       "      <td>0.077011</td>\n",
       "      <td>0.241007</td>\n",
       "      <td>0.116725</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>&lt;s&gt; Context: {}\\n Question: {} [INST] Select t...</td>\n",
       "      <td>0.067073</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.104596</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2-AWQ</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Prompt  Rouge-1 Precision  \\\n",
       "0                                                  {}           0.043831   \n",
       "1                                   [INST] {} [/INST]           0.050388   \n",
       "2                           [INST] {} [/INST] Answer:           0.054357   \n",
       "3   <s>[INST] You are a question answering system....           0.076065   \n",
       "4   <s>Question: {} [INST]Generate a short-form an...           0.067293   \n",
       "5                   Context:{}, Question: {}, Answer:           0.101950   \n",
       "6              [INST] Context:{}\\n Question:{}[/INST]           0.110522   \n",
       "7      [INST] Context:{}\\n Question:{}[/INST] Answer:           0.113430   \n",
       "8   <s>Context:{}\\n [INST] You are a question answ...           0.132495   \n",
       "9   <s>Context:{}\\n Question:{} [INST] Using the i...           0.153285   \n",
       "10                  Context:{}, Question: {}, Answer:           0.074697   \n",
       "11             [INST] Context:{}\\n Question:{}[/INST]           0.063439   \n",
       "12     [INST] Context:{}\\n Question:{}[/INST] Answer:           0.067663   \n",
       "13  <s>Context:{}\\n [INST] You are a question answ...           0.077876   \n",
       "14  <s>Context:{}\\n Question:{} [INST] Using the i...           0.084886   \n",
       "15  <s> Context: {}\\n Question: {} [INST] Select t...           0.041565   \n",
       "16                                                 {}           0.049600   \n",
       "17                                  [INST] {} [/INST]           0.046709   \n",
       "18                          [INST] {} [/INST] Answer:           0.049135   \n",
       "19  <s>[INST] You are a question answering system....           0.056535   \n",
       "20  <s>Question: {} [INST]Generate a short-form an...           0.061924   \n",
       "21                  Context:{}, Question: {}, Answer:           0.135947   \n",
       "22             [INST] Context:{}\\n Question:{}[/INST]           0.138449   \n",
       "23     [INST] Context:{}\\n Question:{}[/INST] Answer:           0.142972   \n",
       "24  <s>Context:{}\\n [INST] You are a question answ...           0.158192   \n",
       "25  <s>Context:{}\\n Question:{} [INST] Using the i...           0.201333   \n",
       "26                  Context:{}, Question: {}, Answer:           0.081210   \n",
       "27             [INST] Context:{}\\n Question:{}[/INST]           0.064266   \n",
       "28     [INST] Context:{}\\n Question:{}[/INST] Answer:           0.061639   \n",
       "29  <s>Context:{}\\n [INST] You are a question answ...           0.059172   \n",
       "30  <s>Context:{}\\n Question:{} [INST] Using the i...           0.077011   \n",
       "31  <s> Context: {}\\n Question: {} [INST] Select t...           0.067073   \n",
       "\n",
       "    Rouge-1 Recall  Rouge-1 F1           Method                         Model  \\\n",
       "0         0.247706    0.074483  without context           Llama-2-7B-Chat-AWQ   \n",
       "1         0.298165    0.086207  without context           Llama-2-7B-Chat-AWQ   \n",
       "2         0.311927    0.092580  without context           Llama-2-7B-Chat-AWQ   \n",
       "3         0.344037    0.124585  without context           Llama-2-7B-Chat-AWQ   \n",
       "4         0.197248    0.100350  without context           Llama-2-7B-Chat-AWQ   \n",
       "5         0.527523    0.170877     with context           Llama-2-7B-Chat-AWQ   \n",
       "6         0.573394    0.185322     with context           Llama-2-7B-Chat-AWQ   \n",
       "7         0.573394    0.189394     with context           Llama-2-7B-Chat-AWQ   \n",
       "8         0.628440    0.218850     with context           Llama-2-7B-Chat-AWQ   \n",
       "9         0.385321    0.219321     with context           Llama-2-7B-Chat-AWQ   \n",
       "10        0.366972    0.124127        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "11        0.348624    0.107345        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "12        0.353211    0.113569        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "13        0.403670    0.130564        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "14        0.188073    0.116976        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "15        0.233945    0.070588        Retriever           Llama-2-7B-Chat-AWQ   \n",
       "16        0.223022    0.081152  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "17        0.237410    0.078060  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "18        0.255396    0.082414  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "19        0.276978    0.093902  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "20        0.169065    0.090646  without context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "21        0.586331    0.220718     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "22        0.629496    0.226978     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "23        0.640288    0.233749     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "24        0.705036    0.258405     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "25        0.543165    0.293774     with context  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "26        0.366906    0.132986        Retriever  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "27        0.327338    0.107438        Retriever  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "28        0.305755    0.102595        Retriever  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "29        0.287770    0.098160        Retriever  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "30        0.241007    0.116725        Retriever  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "31        0.237410    0.104596        Retriever  Mistral-7B-Instruct-v0.2-AWQ   \n",
       "\n",
       "    Sample Size  \n",
       "0            50  \n",
       "1            50  \n",
       "2            50  \n",
       "3            50  \n",
       "4            50  \n",
       "5            50  \n",
       "6            50  \n",
       "7            50  \n",
       "8            50  \n",
       "9            50  \n",
       "10           50  \n",
       "11           50  \n",
       "12           50  \n",
       "13           50  \n",
       "14           50  \n",
       "15           50  \n",
       "16           50  \n",
       "17           50  \n",
       "18           50  \n",
       "19           50  \n",
       "20           50  \n",
       "21           50  \n",
       "22           50  \n",
       "23           50  \n",
       "24           50  \n",
       "25           50  \n",
       "26           50  \n",
       "27           50  \n",
       "28           50  \n",
       "29           50  \n",
       "30           50  \n",
       "31           50  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_answers_with_retrieved_context(questions, prompt, max_new_tokens):\n",
    "    answers = []\n",
    "    for question in questions:\n",
    "        context = retrieve_best_passage(question)\n",
    "        p = prompt.format(context,question)\n",
    "        response = qa_pipeline(p, max_new_tokens=max_new_tokens)\n",
    "        answers.append(response[0]['generated_text'])\n",
    "    return answers\n",
    "prompts = [ \n",
    "    'Context:{}, Question: {}, Answer:',\n",
    "    '[INST] Context:{}\\n Question:{}[/INST]',\n",
    "    '[INST] Context:{}\\n Question:{}[/INST] Answer:',\n",
    "    '<s>Context:{}\\n [INST] You are a question answering system. Based on the above context, generate a short answer to the following question.[/INST]\\n Question: {}',\n",
    "    '<s>Context:{}\\n Question:{} [INST] Using the information provided in the context, generate a short-form answer of either one word or one sentence to the question. [/INST]',\n",
    "    '<s> Context: {}\\n Question: {} [INST] Select the passage from the provided context that best answers the question in either one word or a sentence. [/INST]',\n",
    "          ]\n",
    "results=[]\n",
    "for prompt in prompts:\n",
    "    predicted_answers_retrieved_context = get_answers_with_retrieved_context(questions,prompt, max_new_tokens=50)\n",
    "    pr_retrieved, re_retrieved, f1_retrieved = rouge1(gold_answers, predicted_answers_retrieved_context)\n",
    "    answer = [prompt, pr_retrieved, re_retrieved, f1_retrieved, \"Retriever\", \"Mistral-7B-Instruct-v0.2-AWQ\", 50]\n",
    "    results.append(answer)\n",
    "result_3 = pd.DataFrame(results, columns=['Prompt', 'Rouge-1 Precision', 'Rouge-1 Recall', 'Rouge-1 F1', 'Method', 'Model', 'Sample Size'])\n",
    "result = pd.concat([result, result_3], ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we evaluated the performance of an LLM on the Natural Questions dataset using different prompting strategies. We observed the following:\n",
    "\n",
    "1. **Without Context**:\n",
    "   - ROUGE-1 Precision: *result*\n",
    "   - Recall: *result*\n",
    "   - F1 Score: *result*\n",
    "\n",
    "2. **With Provided Context**:\n",
    "   - ROUGE-1 Precision: *result*\n",
    "   - Recall: *result*\n",
    "   - F1 Score: *result*\n",
    "\n",
    "3. **With Retrieved Context**:\n",
    "   - ROUGE-1 Precision: *result*\n",
    "   - Recall: *result*\n",
    "   - F1 Score: *result*\n",
    "\n",
    "Including context, whether provided or retrieved, ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
